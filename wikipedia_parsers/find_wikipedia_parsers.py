#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–æ–∏—Å–∫ –≤—Å–µ—Ö –ø–∞—Ä—Å–µ—Ä–æ–≤ –í–∏–∫–∏–ø–µ–¥–∏–∏ –≤ –ø—Ä–æ–µ–∫—Ç–µ
"""

import os
import re
import glob

def find_wikipedia_parsers():
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –ø–∞—Ä—Å–µ—Ä—ã –í–∏–∫–∏–ø–µ–¥–∏–∏ –≤ –ø—Ä–æ–µ–∫—Ç–µ"""
    
    print("üîç –ü–û–ò–°–ö –ü–ê–†–°–ï–†–û–í –í–ò–ö–ò–ü–ï–î–ò–ò –í –ü–†–û–ï–ö–¢–ï")
    print("=" * 60)
    
    # –ò—â–µ–º –≤—Å–µ Python —Ñ–∞–π–ª—ã
    python_files = glob.glob("*.py")
    
    wikipedia_parsers = []
    
    for file in python_files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                content = f.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ñ–∞–π–ª —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –í–∏–∫–∏–ø–µ–¥–∏–∏
                if any(keyword in content.lower() for keyword in [
                    'wikipedia', 'wiki', 'en.wikipedia.org', 
                    'parse', '–ø–∞—Ä—Å–µ—Ä', '–ø–∞—Ä—Å–∏–Ω–≥'
                ]):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
                    lines = content.split('\n')
                    
                    # –ò—â–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ/–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                    description = "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
                    for line in lines[:20]:  # –ü–µ—Ä–≤—ã–µ 20 —Å—Ç—Ä–æ–∫
                        if any(keyword in line.lower() for keyword in [
                            '–ø–∞—Ä—Å–µ—Ä', 'parser', '–ø–∞—Ä—Å–∏–Ω–≥', 'parsing',
                            '—Å–æ–±—ã—Ç–∏—è', 'events', '–±–æ–π—Ü—ã', 'fighters',
                            '—Ä–µ–π—Ç–∏–Ω–≥–∏', 'rankings', '–±–æ–∏', 'fights'
                        ]):
                            if '#' in line or '"""' in line or "'''" in line:
                                description = line.strip().replace('#', '').replace('"""', '').replace("'''", '').strip()
                                break
                    
                    # –ò—â–µ–º URL –í–∏–∫–∏–ø–µ–¥–∏–∏
                    wikipedia_urls = re.findall(r'https?://[^\s\'"]*wikipedia[^\s\'"]*', content)
                    
                    # –ò—â–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                    functions = re.findall(r'def\s+(\w*parse\w*|parse_\w+)', content)
                    
                    wikipedia_parsers.append({
                        'file': file,
                        'description': description,
                        'wikipedia_urls': wikipedia_urls,
                        'parse_functions': functions,
                        'size': os.path.getsize(file)
                    })
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file}: {e}")
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞ (–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã –æ–±—ã—á–Ω–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä—ã)
    wikipedia_parsers.sort(key=lambda x: x['size'], reverse=True)
    
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä—Å–µ—Ä–æ–≤: {len(wikipedia_parsers)}")
    print()
    
    for i, parser in enumerate(wikipedia_parsers, 1):
        print(f"üìã {i}. {parser['file']}")
        print(f"   üìù –û–ø–∏—Å–∞–Ω–∏–µ: {parser['description']}")
        print(f"   üìè –†–∞–∑–º–µ—Ä: {parser['size']:,} –±–∞–π—Ç")
        
        if parser['wikipedia_urls']:
            print(f"   üåê URL –í–∏–∫–∏–ø–µ–¥–∏–∏:")
            for url in parser['wikipedia_urls'][:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3 URL
                print(f"      ‚Ä¢ {url}")
        
        if parser['parse_functions']:
            print(f"   üîß –§—É–Ω–∫—Ü–∏–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞:")
            for func in parser['parse_functions'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ñ—É–Ω–∫—Ü–∏–π
                print(f"      ‚Ä¢ {func}")
        
        print()
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É –ø–∞—Ä—Å–µ—Ä–∞
    print("üìä –ì–†–£–ü–ü–ò–†–û–í–ö–ê –ü–û –¢–ò–ü–ê–ú –ü–ê–†–°–ï–†–û–í")
    print("=" * 60)
    
    event_parsers = [p for p in wikipedia_parsers if any(keyword in p['file'].lower() for keyword in ['event', '—Å–æ–±—ã—Ç–∏—è'])]
    fighter_parsers = [p for p in wikipedia_parsers if any(keyword in p['file'].lower() for keyword in ['fighter', '–±–æ–π—Ü', 'rankings', '—Ä–µ–π—Ç–∏–Ω–≥'])]
    fight_parsers = [p for p in wikipedia_parsers if any(keyword in p['file'].lower() for keyword in ['fight', '–±–æ–∏'])]
    other_parsers = [p for p in wikipedia_parsers if p not in event_parsers + fighter_parsers + fight_parsers]
    
    print(f"üé™ –ü–ê–†–°–ï–†–´ –°–û–ë–´–¢–ò–ô ({len(event_parsers)}):")
    for parser in event_parsers:
        print(f"   ‚Ä¢ {parser['file']}")
    
    print(f"\nü•ä –ü–ê–†–°–ï–†–´ –ë–û–ô–¶–û–í –ò –†–ï–ô–¢–ò–ù–ì–û–í ({len(fighter_parsers)}):")
    for parser in fighter_parsers:
        print(f"   ‚Ä¢ {parser['file']}")
    
    print(f"\n‚öîÔ∏è –ü–ê–†–°–ï–†–´ –ë–û–ï–í ({len(fight_parsers)}):")
    for parser in fight_parsers:
        print(f"   ‚Ä¢ {parser['file']}")
    
    print(f"\nüîß –î–†–£–ì–ò–ï –ü–ê–†–°–ï–†–´ ({len(other_parsers)}):")
    for parser in other_parsers:
        print(f"   ‚Ä¢ {parser['file']}")
    
    return wikipedia_parsers

if __name__ == "__main__":
    find_wikipedia_parsers()
