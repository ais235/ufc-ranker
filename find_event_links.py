#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è UFC
"""

import requests
from bs4 import BeautifulSoup

def find_event_links():
    """–ù–∞—Ö–æ–¥–∏—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è UFC"""
    
    print("üîç –ü–û–ò–°–ö –°–°–´–õ–û–ö –ù–ê –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–ï –°–û–ë–´–¢–ò–Ø UFC")
    print("=" * 50)
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get("https://en.wikipedia.org/wiki/List_of_UFC_events", headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Å–æ–±—ã—Ç–∏—è–º–∏
        print("üîç –°—Å—ã–ª–∫–∏ –Ω–∞ –¥—Ä—É–≥–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Å–æ–±—ã—Ç–∏—è–º–∏:")
        event_links = []
        for link in soup.find_all('a', href=True):
            href = link.get('href')
            text = link.get_text(strip=True)
            if 'UFC' in text and ('event' in href.lower() or 'ufc' in href.lower()):
                event_links.append((text, href))
                print(f"  {text} -> {href}")
        
        print(f"\nüìä –ù–∞–π–¥–µ–Ω–æ {len(event_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å–æ–±—ã—Ç–∏—è")
        
        # –ò—â–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ —Å—Å—ã–ª–∫–∏ –Ω–∞ UFC 1-100
        print(f"\nüîç –ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ UFC 1-100:")
        for text, href in event_links:
            if any(f"UFC {i}" in text for i in range(1, 101)):
                print(f"  ‚≠ê {text} -> {href}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    find_event_links()
